cal(m) 1985 1 1
all 2012:1
open data
data(format=xls,org=obs)
tab
set ip_us = 1200*(log(ip) - log(ip{1}))
set inf = 1200*(log(cpi) - log(cpi{1}))
set dummy1 = %if(t==2007:08,1,0)
set dummy = %if(t>=2007:08,1,0)


spgraph(hfields=1,vfields=3)
graph(grid=dummy1,hea="Baker, Bloom, and Davis(2012) Uncertainty Index") 1 ; # uncert
graph(hea="Inflation") 1 ; # inf
graph(hea="Output") 1 ; # ip_us
spgraph(done)
***********************Uncertainty and Inflation********************
compute n=2
dec vect[strings] vlabels(n)
compute vlabels=||"Uncertainty","Inflation"||

dec symm[series] hhs(2,2)

do i= 1,2
	do j=1,i
		set hhs(i,j) / = 0.0
     end do j
end do i

com lags = 9
equation unc uncert
# constant inf{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2) dummy
equation infl inf
# constant inf{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2)
group means unc infl
garch(p=1,q=1,model=means,mvhseries=hhs,rvectors=rv,hmatrices=h,method=bfgs,iters=800,mv=dcc,pmethod=simplex,piters=20) /

compute gstart=%regstart(),gend=%regend()
*
* Proposal density for the increment in independence chain MH is based
* upon the covariance matrix from the GARCH estimates. This is a
* multivariate t with <<nuxx>> degrees of freedom. The scale on FXX and
* the value for NUXX may need to be adjusted in different applications
* to get a reasonable acceptance rate.
*
compute fxx=.1*%decomp(%xx)
compute nuxx=10.0
*
* Start at the ML estimates
*
compute logplast=%logl
compute blast=%beta
compute accept=0
*
compute nburn=200,nkeep=200
*
* This keeps track of the DCC correlations estimates. This is a
* complicated structure since we have, for each draw, one full series
* for each off-diagonal. (For simplicity, this is also saving the
* diagonals, which are, of course, 1's). With a bigger model (longer
* time series or more variables) or more draws, you could run into
* memory issues.
*
dec symm[series[vect]] dcccorr(n,n)
do i=1,n
   do j=1,i
      gset dcccorr(i,j) gstart gend = %zeros(nkeep,1)
   end do j
end do i
*
dec series[symm] hlast
gset hlast gstart gend = h
*
infobox(action=define,progress,lower=-nburn,upper=nkeep) "Independence M-H"
do draw=-nburn,nkeep
   compute btest=blast+%ranmvt(fxx,nuxx)
   *
   * Evaluate the GARCH model at the proposal
   *
   com lags = 9
	equation unc uncert
	# constant inf{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2) dummy
	equation infl inf
	# constant inf{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2)
	group means unc infl
	garch(p=1,q=1,model=means,initial=btest,mvhseries=hhs,rvectors=rv,hmatrices=htest,method=evaluate,iters=800,mv=dcc,pmethod=simplex,piters=20) /
   compute logptest=%logl
   *
   * Carry out the Metropolis test
   *
   compute alpha=exp(logptest-logplast)
   if alpha>1.0.or.%uniform(0.0,1.0)<alpha {
      compute accept=accept+1
      compute blast =btest
      compute logplast=logptest
      gset hlast gstart gend = htest
   }

   infobox(current=draw) %strval(100.0*accept/(draw+nburn+1),"##.##")
   if draw>0 {
      do i=1,n
         do j=1,i
            do t=gstart,gend
               compute dcccorr(i,j)(t)(draw)=%cvtocorr(hlast(t))(i,j)
            end do t
         end do j
      end do i
   }
end do draw
infobox(action=remove)
*
dec vect xcorr(nkeep)
dec symm[series] lower(n,n) upper(n,n) median(n,n)
clear(zeros) lower upper median
*
* Generate the median and 90% confidence band for the DCC correlations.
* For this data set, the period to period movement is large enough
* relative to the spread that the three lines basically end up on top of
* each other. If you graph over a shorter period, you can see at least
* some spread between the upper and lower bounds.
*


set contraction = t>=1990:07.and.t<=1991:03.or.t>=2001:03.and.t<=2001:11.or.t>=2007:12.and.t<=2009:06
set Hamilton = t>=1957:04.and.t<=1958:04.or.t>=1973:03.and.t<=1975:01.or.t>=1979:03.and.t<=1982:03.or.t>=1990:04.and.t<=1992:02.or.t>=2005:01.and.t<2007:01.or.t>=2007:04.and.t<=2008:03


do j=2,n
   do k=1,j-1
      do t=gstart,gend
         ewise xcorr(i)=dcccorr(j,k)(t)(i)
         compute frac=%fractiles(xcorr,||.05,.50,.95||)
         compute lower(j,k)(t)=frac(1)
         compute upper(j,k)(t)=frac(3)
         compute median(j,k)(t)=frac(2)
      end do tme
      graph(grid=Hamilton,patterns,shading=contraction,hea="Correlations Between Uncertainty and Inflation",subhea="Shading=NBER Recessions  Lines=Hamilton Oil Shock Dates",key=below, $
		klabel=||"Dynamic Corrleations","Upper 90% CI","Lower 90%CI"||) 3 ;
      # median(j,k) gstart gend
      # lower(j,k) gstart gend 2
      # upper(j,k) gstart gend 2
   end do k
end do j




***********************Uncertainty and Output********************
compute n=2
dec vect[strings] vlabels(n)
compute vlabels=||"Uncertainty","Output"||

dec symm[series] hhs(2,2)

do i= 1,2
	do j=1,i
		set hhs(i,j) / = 0.0
     end do j
end do i

com lags = 9
equation unc uncert
# constant ip_us{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2) dummy
equation us ip_us
# constant ip_us{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2)
group means unc us
garch(p=1,q=1,model=means,mvhseries=hhs,rvectors=rv,hmatrices=h,method=bfgs,iters=800,mv=dcc,pmethod=simplex,piters=20) /
set cor %regstart() %regend() = hhs(1,2)/sqrt(h(t)(1,1)*h(t)(2,2))
gra 1; # cor
compute gstart=%regstart(),gend=%regend()
*
* Proposal density for the increment in independence chain MH is based
* upon the covariance matrix from the GARCH estimates. This is a
* multivariate t with <<nuxx>> degrees of freedom. The scale on FXX and
* the value for NUXX may need to be adjusted in different applications
* to get a reasonable acceptance rate.
*
compute fxx=.1*%decomp(%xx)
compute nuxx=10.0
*
* Start at the ML estimates
*
compute logplast=%logl
compute blast=%beta
compute accept=0
*
compute nburn=100,nkeep=100
*
* This keeps track of the DCC correlations estimates. This is a
* complicated structure since we have, for each draw, one full series
* for each off-diagonal. (For simplicity, this is also saving the
* diagonals, which are, of course, 1's). With a bigger model (longer
* time series or more variables) or more draws, you could run into
* memory issues.
*
dec symm[series[vect]] dcccorr(n,n)
do i=1,n
   do j=1,i
      gset dcccorr(i,j) gstart gend = %zeros(nkeep,1)
   end do j
end do i
*
dec series[symm] hlast
gset hlast gstart gend = h
*
infobox(action=define,progress,lower=-nburn,upper=nkeep) "Independence M-H"
do draw=-nburn,nkeep
   compute btest=blast+%ranmvt(fxx,nuxx)
   *
   * Evaluate the GARCH model at the proposal
   *
   com lags = 9
	equation unc uncert
	# constant ip_us{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2) dummy
	equation us ip_us
	# constant ip_us{1 to lags} uncert{1 to lags} hhs(1,1) hhs(2,2)
	group means unc us
	garch(p=1,q=1,model=means,initial=btest,mvhseries=hhs,rvectors=rv,hmatrices=htest,method=evaluate,iters=800,mv=dcc,pmethod=simplex,piters=20) /
   compute logptest=%logl
   *
   * Carry out the Metropolis test
   *
   compute alpha=exp(logptest-logplast)
   if alpha>1.0.or.%uniform(0.0,1.0)<alpha {
      compute accept=accept+1
      compute blast =btest
      compute logplast=logptest
      gset hlast gstart gend = htest
   }

   infobox(current=draw) %strval(100.0*accept/(draw+nburn+1),"##.##")
   if draw>0 {
      do i=1,n
         do j=1,i
            do t=gstart,gend
               compute dcccorr(i,j)(t)(draw)=%cvtocorr(hlast(t))(i,j)
            end do t
         end do j
      end do i
   }
end do draw
infobox(action=remove)
*
dec vect xcorr(nkeep)
dec symm[series] lower(n,n) upper(n,n) median(n,n)
clear(zeros) lower upper median
*
* Generate the median and 90% confidence band for the DCC correlations.
* For this data set, the period to period movement is large enough
* relative to the spread that the three lines basically end up on top of
* each other. If you graph over a shorter period, you can see at least
* some spread between the upper and lower bounds.
*


set contraction = t>=1990:07.and.t<=1991:03.or.t>=2001:03.and.t<=2001:11.or.t>=2007:12.and.t<=2009:06
set Hamilton = t>=1957:04.and.t<=1958:04.or.t>=1973:03.and.t<=1975:01.or.t>=1979:03.and.t<=1982:03.or.t>=1990:04.and.t<=1992:02.or.t>=2005:01.and.t<2007:01.or.t>=2007:04.and.t<=2008:03


do j=2,n
   do k=1,j-1
      do t=gstart,gend
         ewise xcorr(i)=dcccorr(j,k)(t)(i)
         compute frac=%fractiles(xcorr,||.05,.50,.95||)
         compute lower(j,k)(t)=frac(1)
         compute upper(j,k)(t)=frac(3)
         compute median(j,k)(t)=frac(2)
      end do tme
      graph(grid=Hamilton,patterns,shading=contraction,hea="Correlations Between Uncertainty and Output",subhea="Shading=NBER Recessions  Lines=Hamilton Oil Shock Dates",key=below, $
		klabel=||"Dynamic Corrleations","Upper 90% CI","Lower 90%CI"||) 3 ;
      # median(j,k) gstart gend
      # lower(j,k) gstart gend 2
      # upper(j,k) gstart gend 2
   end do k
end do j












